{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e458bf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "from torchaudio.transforms import MFCC\n",
    "\n",
    "# Parameters for MFCC extraction and frame standardization\n",
    "sample_rate = 16000\n",
    "n_mfcc = 20\n",
    "melkwargs = {\n",
    "    \"n_fft\": 400,       # frame size of 25ms\n",
    "    \"hop_length\": 160,  # hop size of 10ms\n",
    "    \"n_mels\": 40        # number of Mel filterbanks\n",
    "}\n",
    "max_frames = 250  # Number of time frames to pad/trim to (e.g., ~2s of audio)\n",
    "\n",
    "# Initialize the MFCC transform\n",
    "mfcc_transform = MFCC(\n",
    "    sample_rate=sample_rate,\n",
    "    n_mfcc=n_mfcc,\n",
    "    melkwargs=melkwargs\n",
    ")\n",
    "\n",
    "class LibriSpeechMFCC(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset that wraps LibriSpeech and applies MFCC transform,\n",
    "    with optional padding/truncation and normalization.\n",
    "    Returns:\n",
    "        mfcc: Tensor of shape (n_mfcc, max_frames)\n",
    "        speaker_id: int\n",
    "    \"\"\"\n",
    "    def __init__(self, root=\"./data\", url=\"train-clean-100\", download=False,\n",
    "                 transform=None, max_frames=250):\n",
    "        self.dataset = torchaudio.datasets.LIBRISPEECH(root, url=url, download=download)\n",
    "        self.transform = transform\n",
    "        self.max_frames = max_frames\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        waveform, sr, _, speaker_id, _, _ = self.dataset[idx]\n",
    "        # Resample if needed\n",
    "        if sr != sample_rate:\n",
    "            waveform = torchaudio.functional.resample(waveform, sr, sample_rate)\n",
    "        # Convert to mono if needed\n",
    "        if waveform.size(0) > 1:\n",
    "            waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "        # Apply MFCC transform: output shape (1, n_mfcc, time_frames)\n",
    "        mfcc = self.transform(waveform).squeeze(0)  # now (n_mfcc, time_frames)\n",
    "\n",
    "        # 1) Pad or truncate to fixed number of frames\n",
    "        t = mfcc.shape[1]\n",
    "        if t < self.max_frames:\n",
    "            pad = torch.zeros((n_mfcc, self.max_frames - t))\n",
    "            mfcc = torch.cat((mfcc, pad), dim=1)\n",
    "        else:\n",
    "            mfcc = mfcc[:, :self.max_frames]\n",
    "\n",
    "        # 2) Normalize per coefficient (mean=0, std=1)\n",
    "        mean = mfcc.mean(dim=1, keepdim=True)\n",
    "        std = mfcc.std(dim=1, keepdim=True) + 1e-6\n",
    "        mfcc = (mfcc - mean) / std\n",
    "\n",
    "        return mfcc, speaker_id\n",
    "\n",
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    # Ensure data directory exists and dataset is downloaded\n",
    "    os.makedirs(\"./data\", exist_ok=True)\n",
    "    dataset = LibriSpeechMFCC(\n",
    "        root=\"./data\",\n",
    "        url=\"train-clean-100\",\n",
    "        download=not os.path.isdir(\"./data/LibriSpeech\"),\n",
    "        transform=mfcc_transform,\n",
    "        max_frames=max_frames\n",
    "    )\n",
    "\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=16,\n",
    "        shuffle=True,\n",
    "        num_workers=2\n",
    "    )\n",
    "\n",
    "    # Iterate one batch to check shapes\n",
    "    for batch_mfcc, batch_speaker in dataloader:\n",
    "        print(\"MFCC batch shape:\", batch_mfcc.shape)  # (batch, n_mfcc, max_frames)\n",
    "        print(\"Speaker IDs:\", batch_speaker)\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
